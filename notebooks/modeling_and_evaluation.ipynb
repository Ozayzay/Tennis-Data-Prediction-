{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321871aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BASELINE MODELING - Decision Tree (No Feature Engineering)\n",
    "# ============================================================================\n",
    "\n",
    "# Purpose: Get a baseline performance metric before feature engineering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d962e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data loaded successfully!\n",
      "Shape: (124097, 77)\n",
      "\n",
      "Columns (77):\n",
      "['player1_rank', 'player1_rank_imputed', 'player1_ht', 'player1_age', 'player2_rank', 'player2_rank_imputed', 'player2_ht', 'player2_age', 'player1_won', 'draw_size', 'tourney_date', 'best_of', 'player1_hand_L', 'player1_hand_R', 'player1_hand_U', 'player2_hand_L', 'player2_hand_R', 'player2_hand_U', 'player1_entry_2) A', 'player1_entry_3)'] ...\n",
      "\n",
      "Target variable distribution:\n",
      "player1_won\n",
      "1    62253\n",
      "0    61844\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Load Preprocessed Data\n",
    "# ============================================================================\n",
    "\n",
    "# Load the model-ready dataset (77 features, 124,097 matches)\n",
    "df = pd.read_csv('../data/processed/matches_final_without_player_context.csv')\n",
    "\n",
    "print(f\"‚úì Data loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "print(df.columns.tolist()[:20], \"...\")  # Show first 20 columns\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(df['player1_won'].value_counts())\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc2e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Features and target separated\n",
      "X shape: (124097, 76)\n",
      "y shape: (124097,)\n",
      "\n",
      "Feature columns: ['player1_rank', 'player1_rank_imputed', 'player1_ht', 'player1_age', 'player2_rank', 'player2_rank_imputed', 'player2_ht', 'player2_age', 'draw_size', 'tourney_date']...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124097 entries, 0 to 124096\n",
      "Data columns (total 76 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   player1_rank          124097 non-null  float64\n",
      " 1   player1_rank_imputed  124097 non-null  int64  \n",
      " 2   player1_ht            124097 non-null  float64\n",
      " 3   player1_age           124097 non-null  float64\n",
      " 4   player2_rank          124097 non-null  float64\n",
      " 5   player2_rank_imputed  124097 non-null  int64  \n",
      " 6   player2_ht            124097 non-null  float64\n",
      " 7   player2_age           124097 non-null  float64\n",
      " 8   draw_size             124097 non-null  int64  \n",
      " 9   tourney_date          124097 non-null  int64  \n",
      " 10  best_of               124097 non-null  int64  \n",
      " 11  player1_hand_L        124097 non-null  bool   \n",
      " 12  player1_hand_R        124097 non-null  bool   \n",
      " 13  player1_hand_U        124097 non-null  bool   \n",
      " 14  player2_hand_L        124097 non-null  bool   \n",
      " 15  player2_hand_R        124097 non-null  bool   \n",
      " 16  player2_hand_U        124097 non-null  bool   \n",
      " 17  player1_entry_2) A    124097 non-null  bool   \n",
      " 18  player1_entry_3)      124097 non-null  bool   \n",
      " 19  player1_entry_6)      124097 non-null  bool   \n",
      " 20  player1_entry_6) A    124097 non-null  bool   \n",
      " 21  player1_entry_8)      124097 non-null  bool   \n",
      " 22  player1_entry_A       124097 non-null  bool   \n",
      " 23  player1_entry_AL      124097 non-null  bool   \n",
      " 24  player1_entry_ALT     124097 non-null  bool   \n",
      " 25  player1_entry_Alt     124097 non-null  bool   \n",
      " 26  player1_entry_Direct  124097 non-null  bool   \n",
      " 27  player1_entry_ITF     124097 non-null  bool   \n",
      " 28  player1_entry_J       124097 non-null  bool   \n",
      " 29  player1_entry_LL      124097 non-null  bool   \n",
      " 30  player1_entry_P       124097 non-null  bool   \n",
      " 31  player1_entry_PR      124097 non-null  bool   \n",
      " 32  player1_entry_Q       124097 non-null  bool   \n",
      " 33  player1_entry_S       124097 non-null  bool   \n",
      " 34  player1_entry_SE      124097 non-null  bool   \n",
      " 35  player1_entry_UP      124097 non-null  bool   \n",
      " 36  player1_entry_W       124097 non-null  bool   \n",
      " 37  player1_entry_WC      124097 non-null  bool   \n",
      " 38  player2_entry_3)      124097 non-null  bool   \n",
      " 39  player2_entry_5) A    124097 non-null  bool   \n",
      " 40  player2_entry_6) A    124097 non-null  bool   \n",
      " 41  player2_entry_A       124097 non-null  bool   \n",
      " 42  player2_entry_AL      124097 non-null  bool   \n",
      " 43  player2_entry_ALT     124097 non-null  bool   \n",
      " 44  player2_entry_Alt     124097 non-null  bool   \n",
      " 45  player2_entry_Direct  124097 non-null  bool   \n",
      " 46  player2_entry_I       124097 non-null  bool   \n",
      " 47  player2_entry_ITF     124097 non-null  bool   \n",
      " 48  player2_entry_LL      124097 non-null  bool   \n",
      " 49  player2_entry_P       124097 non-null  bool   \n",
      " 50  player2_entry_PR      124097 non-null  bool   \n",
      " 51  player2_entry_Q       124097 non-null  bool   \n",
      " 52  player2_entry_S       124097 non-null  bool   \n",
      " 53  player2_entry_SE      124097 non-null  bool   \n",
      " 54  player2_entry_W       124097 non-null  bool   \n",
      " 55  player2_entry_WC      124097 non-null  bool   \n",
      " 56  surface_Clay          124097 non-null  bool   \n",
      " 57  surface_Grass         124097 non-null  bool   \n",
      " 58  surface_Hard          124097 non-null  bool   \n",
      " 59  tourney_level_C       124097 non-null  bool   \n",
      " 60  tourney_level_D       124097 non-null  bool   \n",
      " 61  tourney_level_F       124097 non-null  bool   \n",
      " 62  tourney_level_G       124097 non-null  bool   \n",
      " 63  tourney_level_M       124097 non-null  bool   \n",
      " 64  tourney_level_O       124097 non-null  bool   \n",
      " 65  round_F               124097 non-null  bool   \n",
      " 66  round_Q1              124097 non-null  bool   \n",
      " 67  round_Q2              124097 non-null  bool   \n",
      " 68  round_Q3              124097 non-null  bool   \n",
      " 69  round_QF              124097 non-null  bool   \n",
      " 70  round_R128            124097 non-null  bool   \n",
      " 71  round_R16             124097 non-null  bool   \n",
      " 72  round_R32             124097 non-null  bool   \n",
      " 73  round_R64             124097 non-null  bool   \n",
      " 74  round_RR              124097 non-null  bool   \n",
      " 75  round_SF              124097 non-null  bool   \n",
      "dtypes: bool(65), float64(6), int64(5)\n",
      "memory usage: 18.1 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Split Features and Target\n",
    "# ============================================================================\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "# AXIS EXPLANATION: \n",
    "X = df.drop('player1_won', axis=1)\n",
    "y = df['player1_won']\n",
    "\n",
    "print(f\"‚úì Features and target separated\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {X.columns.tolist()[:10]}...\")  # Show first 10\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b82f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data split by tournament date\n",
      "\n",
      "Train set (2014-2022): 96,328 matches (77.6%)\n",
      "Validation set (2023): 13,584 matches (10.9%)\n",
      "Test set (2024):       14,185 matches (11.4%)\n",
      "\n",
      "Features per set: 75 (tourney_date dropped)\n",
      "\n",
      "Class balance in train set:\n",
      "player1_won\n",
      "1    0.501433\n",
      "0    0.498567\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Train/Validation/Test Split by Date\n",
    "# ============================================================================\n",
    "\n",
    "# Split based on tourney_date column\n",
    "# Train: 2014-2022 (dates < 20230000)\n",
    "# Validation: 2023 (20230000 <= dates < 20240000)\n",
    "# Test: 2024 (dates >= 20240000)\n",
    "\n",
    "# Split the dataframe first\n",
    "train_df = df[df['tourney_date'] < 20230000].copy()\n",
    "val_df = df[(df['tourney_date'] >= 20230000) & (df['tourney_date'] < 20240000)].copy()\n",
    "test_df = df[df['tourney_date'] >= 20240000].copy()\n",
    "\n",
    "# Now separate X and y for each split, dropping tourney_date from features\n",
    "X_train = train_df.drop(['player1_won', 'tourney_date'], axis=1)\n",
    "y_train = train_df['player1_won']\n",
    "\n",
    "X_val = val_df.drop(['player1_won', 'tourney_date'], axis=1)\n",
    "y_val = val_df['player1_won']\n",
    "\n",
    "X_test = test_df.drop(['player1_won', 'tourney_date'], axis=1)\n",
    "y_test = test_df['player1_won']\n",
    "\n",
    "print(f\"‚úì Data split by tournament date\")\n",
    "print(f\"\\nTrain set (2014-2022): {X_train.shape[0]:,} matches ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation set (2023): {X_val.shape[0]:,} matches ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set (2024):       {X_test.shape[0]:,} matches ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nFeatures per set: {X_train.shape[1]} (tourney_date dropped)\")\n",
    "print(f\"\\nClass balance in train set:\")\n",
    "print(y_train.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080d849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Features scaled using StandardScaler\n",
      "Original feature range example (player1_rank): 1 to 2258\n",
      "Scaled feature range: ~-3 to ~+3 (standardized)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Train Models\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize Decision Tree with basic parameters\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=10,  \n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Train the Decision tree model on TRAINING SET ONLY\n",
    "# print(\"Training Decision Tree...\")\n",
    "# dt_model.fit(X_train, y_train)\n",
    "# print(\"‚úì Model trained successfully!\")\n",
    "\n",
    "# # Get predictions on all three sets\n",
    "# y_train_pred = dt_model.predict(X_train)\n",
    "# y_val_pred = dt_model.predict(X_val)\n",
    "# y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"BASELINE DECISION TREE PERFORMANCE\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "# Initialize Random Forest with basic parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42, # Because remember that we randomly choose features for each tree and a subset of the data for each tree\n",
    "    max_depth=10,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    max_features= None\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"training random forest...\")\n",
    "# rf_model.fit(X_train,y_train)\n",
    "# print(\"‚úì Model trained successfully!\")\n",
    "\n",
    "# #Get predictions on all three sets for Random Forest\n",
    "# y_train_pred = rf_model.predict(X_train)\n",
    "# y_val_pred = rf_model.predict(X_val)\n",
    "# y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# print(\"Baseline Random Forest model trained successfully!\")\n",
    "\n",
    "# #########################\n",
    "\n",
    "\n",
    "#intialize Logistic Regression\n",
    "\n",
    "# Can use Logistic Regression for when the label is binary (0 or 1)\n",
    "\n",
    "# Logistic Regression requires feature scaling\n",
    "# Create and fit scaler on training data only\n",
    "# *** Impotrant **** \n",
    "# Why Fit_transform on training data only?\n",
    "# Because we want to learn the scaling parameters from the training data i.e the mean and std for each feature \n",
    "# We don't want to leak any information from the training data to the test data\n",
    "# We want to evaluate the model on the test data as if it were new data so we only have std and mean from the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # *** Impotrant **** \n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features scaled using StandardScaler\")\n",
    "print(f\"Original feature range example (player1_rank): {X_train['player1_rank'].min():.0f} to {X_train['player1_rank'].max():.0f}\")\n",
    "print(f\"Scaled feature range: ~-3 to ~+3 (standardized)\")\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# # Train the model on SCALED training data\n",
    "# print(\"\\nTraining Logistic Regression...\")\n",
    "# lr_model.fit(X_train_scaled, y_train)\n",
    "# print(\"‚úì Model trained successfully!\")\n",
    "\n",
    "# # Get predictions on all three sets (scaled)\n",
    "# y_train_pred = lr_model.predict(X_train_scaled)\n",
    "# y_val_pred = lr_model.predict(X_val_scaled)\n",
    "# y_test_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"LOGISTIC REGRESSION PERFORMANCE\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b67f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, precision, recall, f1\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate on all sets\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(y_train, y_train_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(y_val, y_val_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(y_test, y_test_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Evaluate Model Performance\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate and display evaluation metrics\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate on all sets\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "val_metrics = evaluate_model(y_val, y_val_pred, \"Validation\")\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Check for overfitting\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERFITTING CHECK:\")\n",
    "print(\"=\"*70)\n",
    "train_acc, val_acc, test_acc = train_metrics[0], val_metrics[0], test_metrics[0]\n",
    "print(f\"Train Accuracy:      {train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy:       {test_acc:.4f}\")\n",
    "print(f\"\\nTrain-Val Gap:  {(train_acc - val_acc)*100:.2f}%\")\n",
    "print(f\"Train-Test Gap: {(train_acc - test_acc)*100:.2f}%\")\n",
    "\n",
    "if train_acc - val_acc > 0.05:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Significant overfitting detected (>5% gap)\")\n",
    "else:\n",
    "    print(\"\\n‚úì Model generalization looks reasonable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47099e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Confusion Matrix and Classification Report\n",
    "# ============================================================================\n",
    "\n",
    "# Validation set confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX (Validation Set)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{cm_val}\")\n",
    "print(f\"\\nTrue Negatives (TN):  {cm_val[0,0]:,} (Player1 lost, predicted lost)\")\n",
    "print(f\"False Positives (FP): {cm_val[0,1]:,} (Player1 lost, predicted won)\")\n",
    "print(f\"False Negatives (FN): {cm_val[1,0]:,} (Player1 won, predicted lost)\")\n",
    "print(f\"True Positives (TP):  {cm_val[1,1]:,} (Player1 won, predicted won)\")\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Player1 Lost (0)', 'Player1 Won (1)'],\n",
    "            yticklabels=['Player1 Lost (0)', 'Player1 Won (1)'])\n",
    "plt.title('Confusion Matrix - Validation Set', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT (Validation Set)\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_val, y_val_pred, \n",
    "                          target_names=['Player1 Lost', 'Player1 Won']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Feature Importance Analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': dt_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize top 15 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15 = feature_importance.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_15)), top_15['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Most Important Features - Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save feature importance to CSV\n",
    "feature_importance.to_csv('../results/baseline_dt_feature_importance.csv', index=False)\n",
    "print(\"\\n‚úì Feature importance saved to '../results/baseline_dt_feature_importance.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Summary and Next Steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä MODEL: Decision Tree Classifier (No Feature Engineering)\")\n",
    "print(f\"\\nüìÅ DATASET:\")\n",
    "print(f\"   - Total matches: {len(df):,}\")\n",
    "print(f\"   - Features: {X.shape[1]}\")\n",
    "print(f\"   - Train: {len(X_train):,} matches (2014-2022)\")\n",
    "print(f\"   - Validation: {len(X_val):,} matches (2023)\")\n",
    "print(f\"   - Test: {len(X_test):,} matches (2024)\")\n",
    "\n",
    "print(f\"\\nüéØ PERFORMANCE:\")\n",
    "print(f\"   - Train Accuracy:      {train_metrics[0]:.4f} ({train_metrics[0]*100:.2f}%)\")\n",
    "print(f\"   - Validation Accuracy: {val_metrics[0]:.4f} ({val_metrics[0]*100:.2f}%)\")\n",
    "print(f\"   - Test Accuracy:       {test_metrics[0]:.4f} ({test_metrics[0]*100:.2f}%)\")\n",
    "print(f\"   - Validation F1-Score: {val_metrics[3]:.4f}\")\n",
    "\n",
    "print(f\"\\nüîë KEY INSIGHTS:\")\n",
    "print(f\"   - This is the BASELINE before feature engineering\")\n",
    "print(f\"   - Top features are mostly rank-related (player1_rank, player2_rank)\")\n",
    "print(f\"   - Overfitting gap: {(train_metrics[0] - val_metrics[0])*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìù NEXT STEPS:\")\n",
    "print(f\"   1. Feature Engineering (rank_diff, age_diff, surface win rates)\")\n",
    "print(f\"   2. Try other models (Random Forest, XGBoost, Logistic Regression)\")\n",
    "print(f\"   3. Hyperparameter tuning to reduce overfitting\")\n",
    "print(f\"   4. Compare baseline vs engineered feature performance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
